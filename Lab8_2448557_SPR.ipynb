{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "984d17ab"
      },
      "source": [
        "# Task\n",
        "Implement a Hidden Markov Model (HMM) for speech recognition. This includes defining initial, transition, and emission probabilities for phonemes ('/s/', '/p/', '/ie:/', '/tS/') and observations ('Energy', 'Pitch', 'Duration'), displaying these parameters, generating an acoustic observation sequence for the word 'speech', and then using the Viterbi algorithm to infer the most likely phoneme sequence from the generated observations. Finally, summarize the HMM implementation, the generated sequences, and the Viterbi algorithm's results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed769556"
      },
      "source": [
        "## Define HMM Parameters\n",
        "\n",
        "### Subtask:\n",
        "Represent the initial probabilities (P('/s/')=1), transition probabilities, and emission probabilities for the phonemes and observations using suitable Python data structures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f0818f1"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining the HMM parameters: phonemes, observations, initial probabilities, transition probabilities, and emission probabilities using Python data structures. I will define these as lists and dictionaries, using placeholder values where specific probabilities are not provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af335f8f",
        "outputId": "02e0af50-6dc4-408e-dcdf-3541e6efc07d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Define a list of phonemes (states)\n",
        "phonemes = ['/s/', '/p/', '/ie:/', '/tS/']\n",
        "\n",
        "# 2. Define a list of observations\n",
        "observations = ['Energy', 'Pitch', 'Duration']\n",
        "\n",
        "# 3. Create a dictionary for initial probabilities\n",
        "initial_probabilities = {'/s/': 1.0, '/p/': 0.0, '/ie:/': 0.0, '/tS/': 0.0}\n",
        "\n",
        "# 4. Create a dictionary for transition probabilities (placeholder values)\n",
        "# Ensure probabilities for each state sum to 1\n",
        "transition_probabilities = {\n",
        "    '/s/': {'/s/': 0.2, '/p/': 0.8, '/ie:/': 0.0, '/tS/': 0.0}, # Example: from /s/ to /p/\n",
        "    '/p/': {'/s/': 0.0, '/p/': 0.3, '/ie:/': 0.7, '/tS/': 0.0}, # Example: from /p/ to /ie:/\n",
        "    '/ie:/': {'/s/': 0.0, '/p/': 0.0, '/ie:/': 0.6, '/tS/': 0.4}, # Example: from /ie:/ to /tS/\n",
        "    '/tS/': {'/s/': 0.1, '/p/': 0.0, '/ie:/': 0.0, '/tS/': 0.9} # Example: back to /s/ or stay /tS/\n",
        "}\n",
        "\n",
        "# 5. Create a dictionary for emission probabilities (placeholder values)\n",
        "# Ensure probabilities for each state's emissions sum to 1\n",
        "emission_probabilities = {\n",
        "    '/s/': {'Energy': 0.5, 'Pitch': 0.3, 'Duration': 0.2},\n",
        "    '/p/': {'Energy': 0.4, 'Pitch': 0.4, 'Duration': 0.2},\n",
        "    '/ie:/': {'Energy': 0.2, 'Pitch': 0.5, 'Duration': 0.3},\n",
        "    '/tS/': {'Energy': 0.3, 'Pitch': 0.2, 'Duration': 0.5}\n",
        "}\n",
        "\n",
        "print(\"Phonemes (States):\", phonemes)\n",
        "print(\"Observations:\", observations)\n",
        "print(\"Initial Probabilities:\", initial_probabilities)\n",
        "print(\"Transition Probabilities:\", transition_probabilities)\n",
        "print(\"Emission Probabilities:\", emission_probabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phonemes (States): ['/s/', '/p/', '/ie:/', '/tS/']\n",
            "Observations: ['Energy', 'Pitch', 'Duration']\n",
            "Initial Probabilities: {'/s/': 1.0, '/p/': 0.0, '/ie:/': 0.0, '/tS/': 0.0}\n",
            "Transition Probabilities: {'/s/': {'/s/': 0.2, '/p/': 0.8, '/ie:/': 0.0, '/tS/': 0.0}, '/p/': {'/s/': 0.0, '/p/': 0.3, '/ie:/': 0.7, '/tS/': 0.0}, '/ie:/': {'/s/': 0.0, '/p/': 0.0, '/ie:/': 0.6, '/tS/': 0.4}, '/tS/': {'/s/': 0.1, '/p/': 0.0, '/ie:/': 0.0, '/tS/': 0.9}}\n",
            "Emission Probabilities: {'/s/': {'Energy': 0.5, 'Pitch': 0.3, 'Duration': 0.2}, '/p/': {'Energy': 0.4, 'Pitch': 0.4, 'Duration': 0.2}, '/ie:/': {'Energy': 0.2, 'Pitch': 0.5, 'Duration': 0.3}, '/tS/': {'Energy': 0.3, 'Pitch': 0.2, 'Duration': 0.5}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31fdc4e8"
      },
      "source": [
        "## Display HMM Parameters\n",
        "\n",
        "### Subtask:\n",
        "Write a Python function to neatly display the defined initial probabilities, placeholder transition matrix, and emission matrix. Use pandas DataFrames for clear presentation of the matrices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "889a4f58"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires displaying the HMM parameters using pandas DataFrames and Series for clear presentation. I will import pandas, then convert the initial probabilities to a Series and the transition and emission probabilities to DataFrames, printing each with appropriate labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbbe4d94",
        "outputId": "a929ae8d-885f-4554-8e1e-fdc6003bdbe5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Display Initial Probabilities as a Series\n",
        "initial_prob_series = pd.Series(initial_probabilities)\n",
        "print(\"Initial Probabilities:\")\n",
        "print(initial_prob_series)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Display Transition Probabilities as a DataFrame\n",
        "transition_df = pd.DataFrame(transition_probabilities)\n",
        "print(\"Transition Probabilities:\")\n",
        "print(transition_df)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Display Emission Probabilities as a DataFrame\n",
        "emission_df = pd.DataFrame(emission_probabilities)\n",
        "print(\"Emission Probabilities:\")\n",
        "print(emission_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Probabilities:\n",
            "/s/      1.0\n",
            "/p/      0.0\n",
            "/ie:/    0.0\n",
            "/tS/     0.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "Transition Probabilities:\n",
            "       /s/  /p/  /ie:/  /tS/\n",
            "/s/    0.2  0.0    0.0   0.1\n",
            "/p/    0.8  0.3    0.0   0.0\n",
            "/ie:/  0.0  0.7    0.6   0.0\n",
            "/tS/   0.0  0.0    0.4   0.9\n",
            "\n",
            "\n",
            "Emission Probabilities:\n",
            "          /s/  /p/  /ie:/  /tS/\n",
            "Energy    0.5  0.4    0.2   0.3\n",
            "Pitch     0.3  0.4    0.5   0.2\n",
            "Duration  0.2  0.2    0.3   0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e94325b6"
      },
      "source": [
        "## Generate Observation Sequence\n",
        "\n",
        "### Subtask:\n",
        "Using the fixed phoneme sequence for the word 'speech' (i.e., ['/s/', '/p/', '/ie:/', '/tS/']), generate a corresponding acoustic observation sequence by probabilistically selecting observations based on the defined emission probabilities for each phoneme.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4108b9ae"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to generate an acoustic observation sequence for the word 'speech' by probabilistically selecting observations based on the emission probabilities for each phoneme. This involves iterating through the phoneme sequence, looking up emission probabilities, and using `np.random.choice` to select observations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49364890",
        "outputId": "44986b7b-6449-4734-d359-691414d87259"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Define the fixed phoneme sequence for the word 'speech'\n",
        "phoneme_sequence_speech = ['/s/', '/p/', '/ie:/', '/tS/']\n",
        "\n",
        "# 2. Initialize an empty list for the generated acoustic observation sequence\n",
        "acoustic_observation_sequence = []\n",
        "\n",
        "# 3. Iterate through each phoneme in the defined fixed phoneme sequence\n",
        "for phoneme in phoneme_sequence_speech:\n",
        "    # 4. Access its emission probabilities from the emission_probabilities dictionary\n",
        "    current_emission_probs = emission_probabilities[phoneme]\n",
        "\n",
        "    # Prepare observations and their probabilities for np.random.choice\n",
        "    obs_choices = list(current_emission_probs.keys())\n",
        "    obs_weights = list(current_emission_probs.values())\n",
        "\n",
        "    # 5. Use np.random.choice() to randomly select an observation\n",
        "    selected_observation = np.random.choice(obs_choices, p=obs_weights)\n",
        "\n",
        "    # 6. Append the selected observation to the acoustic observation sequence list\n",
        "    acoustic_observation_sequence.append(selected_observation)\n",
        "\n",
        "# 7. Print the generated acoustic observation sequence\n",
        "print(\"Phoneme sequence for 'speech':\", phoneme_sequence_speech)\n",
        "print(\"Generated acoustic observation sequence:\", acoustic_observation_sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phoneme sequence for 'speech': ['/s/', '/p/', '/ie:/', '/tS/']\n",
            "Generated acoustic observation sequence: [np.str_('Duration'), np.str_('Pitch'), np.str_('Duration'), np.str_('Duration')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "543ba903"
      },
      "source": [
        "## Apply Viterbi Algorithm\n",
        "\n",
        "### Subtask:\n",
        "Implement the Viterbi algorithm to infer the most likely sequence of hidden phonemes (states) given the generated acoustic observation sequence and the defined HMM parameters (initial, transition, and emission probabilities).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70a72343"
      },
      "source": [
        "## Apply Viterbi Algorithm\n",
        "\n",
        "### Subtask:\n",
        "Implement the Viterbi algorithm to infer the most likely sequence of hidden phonemes (states) given the generated acoustic observation sequence and the defined HMM parameters (initial, transition, and emission probabilities).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540e601d"
      },
      "source": [
        "**Reasoning**:\n",
        "The Viterbi algorithm is used to find the most likely sequence of hidden states (phonemes) given a sequence of observations. It works in three main steps:\n",
        "1.  **Initialization**: Set up data structures to store probabilities and backpointers for each state at each time step. The initial probabilities for the first observation are calculated.\n",
        "2.  **Recursion (Forward Pass)**: For each subsequent observation, calculate the probability of being in each state, considering all possible previous states and their transition and emission probabilities. Store the maximum probability and the path (backpointer) that led to it.\n",
        "3.  **Termination and Path Backtracking**: Find the most likely final state and then trace back through the backpointers to reconstruct the most likely sequence of hidden states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54f6927"
      },
      "source": [
        "**Reasoning**:\n",
        "I will implement the Viterbi algorithm using the defined HMM parameters and the generated acoustic observation sequence. This involves initializing probability and path matrices, performing a forward pass to fill these matrices, and then backtracking to find the most likely sequence of hidden states.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "61a32b48",
        "outputId": "fa468a3e-b8b3-4c5b-a992-f86632833e67"
      },
      "source": [
        "def viterbi(obs_sequence, states, start_p, trans_p, emit_p):\n",
        "    # 1. Initialize Viterbi path probability matrix (V) and backpointer matrix (path)\n",
        "    T = len(obs_sequence) # Number of observations\n",
        "    N = len(states)       # Number of hidden states (phonemes)\n",
        "\n",
        "    # V[t][i] stores the probability of the most probable path ending at state i at time t\n",
        "    V = np.zeros((N, T))\n",
        "\n",
        "    # path[t][i] stores the index of the previous state in the most probable path ending at state i at time t\n",
        "    path = np.zeros((N, T), dtype=int)\n",
        "\n",
        "    # Create mappings for state names to indices and observation names to indices for easier lookup\n",
        "    state_to_idx = {state: i for i, state in enumerate(states)}\n",
        "    idx_to_state = {i: state for i, state in enumerate(states)}\n",
        "\n",
        "    # 2. Initialization step for the first observation\n",
        "    first_obs = obs_sequence[0]\n",
        "    for i, state in enumerate(states):\n",
        "        # Probability of starting in state 'state' and emitting 'first_obs'\n",
        "        V[i, 0] = start_p.get(state, 0.0) * emit_p[state].get(first_obs, 0.0)\n",
        "\n",
        "    # 3. Recursion step (Forward Pass)\n",
        "    for t in range(1, T): # For each subsequent observation\n",
        "        current_obs = obs_sequence[t]\n",
        "        for j, current_state in enumerate(states): # For each current state\n",
        "            max_prob = 0.0\n",
        "            best_prev_state_idx = -1\n",
        "\n",
        "            for i, prev_state in enumerate(states): # For each possible previous state\n",
        "                # V[i, t-1]: probability of best path ending in prev_state at time t-1\n",
        "                # trans_p[prev_state][current_state]: transition probability from prev_state to current_state\n",
        "                # emit_p[current_state][current_obs]: emission probability of current_obs from current_state\n",
        "                prob = V[i, t-1] * trans_p[prev_state].get(current_state, 0.0) * emit_p[current_state].get(current_obs, 0.0)\n",
        "\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    best_prev_state_idx = i\n",
        "\n",
        "            V[j, t] = max_prob\n",
        "            path[j, t] = best_prev_state_idx\n",
        "\n",
        "    # 4. Termination and Path Backtracking\n",
        "    # Find the most probable last state\n",
        "    last_state_idx = np.argmax(V[:, T - 1])\n",
        "    max_final_prob = V[last_state_idx, T - 1]\n",
        "\n",
        "    # Reconstruct the most likely path\n",
        "    most_likely_path = [None] * T\n",
        "    most_likely_path[T - 1] = idx_to_state[last_state_idx]\n",
        "\n",
        "    for t in range(T - 2, -1, -1):\n",
        "        last_state_idx = path[last_state_idx, t + 1]\n",
        "        most_likely_path[t] = idx_to_state[last_state_idx]\n",
        "\n",
        "    return most_likely_path, max_final_prob, V, path\n",
        "\n",
        "# Apply the Viterbi algorithm\n",
        "most_likely_phoneme_sequence, final_prob, v_matrix, path_matrix = viterbi(\n",
        "    acoustic_observation_sequence,\n",
        "    phonemes,\n",
        "    initial_probabilities,\n",
        "    transition_probabilities,\n",
        "    emission_probabilities\n",
        ")\n",
        "\n",
        "print(\"Generated Acoustic Observation Sequence:\", acoustic_observation_sequence)\n",
        "print(\"Most Likely Phoneme Sequence (Viterbi):\","
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-2533960517.py, line 67)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2533960517.py\"\u001b[0;36m, line \u001b[0;32m67\u001b[0m\n\u001b[0;31m    print(\"Most Likely Phoneme Sequence (Viterbi):\",\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f18043e0"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed due to an incomplete `print` statement. I need to complete the `print` statement to correctly display the `most_likely_phoneme_sequence` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fe8058d",
        "outputId": "e6807d63-8f30-437c-f7eb-78a92d9e6429"
      },
      "source": [
        "def viterbi(obs_sequence, states, start_p, trans_p, emit_p):\n",
        "    # 1. Initialize Viterbi path probability matrix (V) and backpointer matrix (path)\n",
        "    T = len(obs_sequence) # Number of observations\n",
        "    N = len(states)       # Number of hidden states (phonemes)\n",
        "\n",
        "    # V[t][i] stores the probability of the most probable path ending at state i at time t\n",
        "    V = np.zeros((N, T))\n",
        "\n",
        "    # path[t][i] stores the index of the previous state in the most probable path ending at state i at time t\n",
        "    path = np.zeros((N, T), dtype=int)\n",
        "\n",
        "    # Create mappings for state names to indices and observation names to indices for easier lookup\n",
        "    state_to_idx = {state: i for i, state in enumerate(states)}\n",
        "    idx_to_state = {i: state for i, state in enumerate(states)}\n",
        "\n",
        "    # 2. Initialization step for the first observation\n",
        "    first_obs = obs_sequence[0]\n",
        "    for i, state in enumerate(states):\n",
        "        # Probability of starting in state 'state' and emitting 'first_obs'\n",
        "        V[i, 0] = start_p.get(state, 0.0) * emit_p[state].get(first_obs, 0.0)\n",
        "\n",
        "    # 3. Recursion step (Forward Pass)\n",
        "    for t in range(1, T): # For each subsequent observation\n",
        "        current_obs = obs_sequence[t]\n",
        "        for j, current_state in enumerate(states): # For each current state\n",
        "            max_prob = 0.0\n",
        "            best_prev_state_idx = -1\n",
        "\n",
        "            for i, prev_state in enumerate(states): # For each possible previous state\n",
        "                # V[i, t-1]: probability of best path ending in prev_state at time t-1\n",
        "                # trans_p[prev_state][current_state]: transition probability from prev_state to current_state\n",
        "                # emit_p[current_state][current_obs]: emission probability of current_obs from current_state\n",
        "                prob = V[i, t-1] * trans_p[prev_state].get(current_state, 0.0) * emit_p[current_state].get(current_obs, 0.0)\n",
        "\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    best_prev_state_idx = i\n",
        "\n",
        "            V[j, t] = max_prob\n",
        "            path[j, t] = best_prev_state_idx\n",
        "\n",
        "    # 4. Termination and Path Backtracking\n",
        "    # Find the most probable last state\n",
        "    last_state_idx = np.argmax(V[:, T - 1])\n",
        "    max_final_prob = V[last_state_idx, T - 1]\n",
        "\n",
        "    # Reconstruct the most likely path\n",
        "    most_likely_path = [None] * T\n",
        "    most_likely_path[T - 1] = idx_to_state[last_state_idx]\n",
        "\n",
        "    for t in range(T - 2, -1, -1):\n",
        "        last_state_idx = path[last_state_idx, t + 1]\n",
        "        most_likely_path[t] = idx_to_state[last_state_idx]\n",
        "\n",
        "    return most_likely_path, max_final_prob, V, path\n",
        "\n",
        "# Apply the Viterbi algorithm\n",
        "most_likely_phoneme_sequence, final_prob, v_matrix, path_matrix = viterbi(\n",
        "    acoustic_observation_sequence,\n",
        "    phonemes,\n",
        "    initial_probabilities,\n",
        "    transition_probabilities,\n",
        "    emission_probabilities\n",
        ")\n",
        "\n",
        "print(\"Generated Acoustic Observation Sequence:\", acoustic_observation_sequence)\n",
        "print(\"Most Likely Phoneme Sequence (Viterbi):\", most_likely_phoneme_sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Acoustic Observation Sequence: [np.str_('Duration'), np.str_('Pitch'), np.str_('Duration'), np.str_('Duration')]\n",
            "Most Likely Phoneme Sequence (Viterbi): ['/s/', '/p/', '/ie:/', '/tS/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5275dbce"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary of the HMM implementation, the generated phoneme (fixed) and observation sequences, and the results of the Viterbi algorithm (inferred phoneme sequence).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4267962"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**HMM Implementation Summary:**\n",
        "The Hidden Markov Model (HMM) was implemented by defining four phonemes (`/s/`, `/p/`, `/ie:/`, `/tS/`) as states and three acoustic features (`Energy`, `Pitch`, `Duration`) as observations. Initial probabilities were set such that the word 'speech' always starts with `/s/` (P('/s/')=1.0). Transition probabilities defined how one phoneme can follow another (e.g., a high probability of transitioning from `/s/` to `/p/`). Emission probabilities specified the likelihood of observing a particular acoustic feature given a specific phoneme (e.g., `/s/` is more likely to emit 'Energy' or 'Pitch').\n",
        "\n",
        "**Generated Phoneme (fixed) and Observation Sequences Summary:**\n",
        "The fixed phoneme sequence for the word 'speech' was `['/s/', '/p/', '/ie:/', '/tS/']`. Based on the defined emission probabilities for each phoneme, a corresponding acoustic observation sequence was probabilistically generated as `['Duration', 'Pitch', 'Duration', 'Duration']`.\n",
        "\n",
        "**Viterbi Algorithm Results (Inferred Phoneme Sequence) Summary:**\n",
        "The Viterbi algorithm successfully inferred the most likely phoneme sequence from the generated acoustic observation sequence `['Duration', 'Pitch', 'Duration', 'Duration']`. The inferred sequence was `['/s/', '/p/', '/ie:/', '/tS/']`, which perfectly matched the original fixed phoneme sequence used for generating the observations.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The HMM was defined with 4 phonemes (`/s/`, `/p/`, `/ie:/`, `/tS/`) as hidden states and 3 acoustic observations (`Energy`, `Pitch`, `Duration`).\n",
        "*   Initial probabilities were set to 1.0 for the starting phoneme `/s/`, and 0.0 for others.\n",
        "*   Transition and emission probabilities were defined, ensuring each phoneme's outgoing transitions and emissions sum to 1.0.\n",
        "*   HMM parameters were clearly presented using pandas Series and DataFrames, enhancing readability.\n",
        "*   For the fixed phoneme sequence `['/s/', '/p/', '/ie:/', '/tS/']` representing 'speech', the generated acoustic observation sequence was `['Duration', 'Pitch', 'Duration', 'Duration']`.\n",
        "*   The Viterbi algorithm successfully inferred the most likely phoneme sequence as `['/s/', '/p/', '/ie:/', '/tS/']` from the generated observations, demonstrating its effectiveness in recovering the underlying states.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The successful recovery of the original phoneme sequence by the Viterbi algorithm, even with probabilistically generated observations, indicates the HMM parameters are well-defined for this specific example. This validates the fundamental principle of using HMMs for sequence inference in applications like speech recognition.\n",
        "*   Next steps could involve testing the HMM and Viterbi algorithm with more complex phoneme sequences, a larger vocabulary, or by integrating real-world speech data to evaluate its performance under more realistic conditions.\n"
      ]
    }
  ]
}